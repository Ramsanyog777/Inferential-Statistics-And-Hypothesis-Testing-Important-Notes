{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Hypothesis Testing\n",
        "\n",
        "Hypothesis testing is a statistical method used in various industries to make decisions or draw conclusions about a population based on sample data. Here are several industry-based examples of hypothesis testing:\n",
        "\n",
        "**1.Pharmaceuticals: Drug Efficacy**\n",
        "\n",
        "**Scenario:** A pharmaceutical company develops a new drug to treat a specific medical condition and wants to determine if the drug is more effective than the existing treatment.\n",
        "Hypothesis:\n",
        "- `Null Hypothesis (H0):` The new drug is equally effective as the existing treatment.\n",
        "- `Alternative Hypothesis (H1):` The new drug is more effective than the existing treatment.\n",
        "\n",
        "**Test:** A clinical trial is conducted, and statistical tests are performed to analyze the data and determine if there is enough evidence to reject the null hypothesis in favor of the alternative.\n",
        "\n",
        "**2.Finance: Investment Strategy**\n",
        "\n",
        "**Scenario:** A financial analyst proposes a new investment strategy that claims to outperform the current market average.\n",
        "Hypothesis:\n",
        "- **Null Hypothesis (H0):** The new investment strategy does not outperform the market average.\n",
        "- **Alternative Hypothesis (H1):** The new investment strategy outperforms the market average.\n",
        "\n",
        "**Test:** Historical data is collected and analyzed using statistical tests to assess whether the returns from the proposed strategy are significantly different from the market average.\n",
        "\n",
        "**3.Manufacturing: Production Process Improvement**\n",
        "\n",
        "**Scenario:** A manufacturing plant implements changes to its production process with the goal of reducing defects in the final product.\n",
        "Hypothesis:\n",
        "- **Null Hypothesis (H0):** The changes to the production process do not reduce defects.\n",
        "- **Alternative Hypothesis (H1):** The changes to the production process reduce defects.\n",
        "\n",
        "**Test:** Data on defect rates before and after the changes are collected, and statistical tests are performed to determine if there is a significant improvement.\n",
        "\n",
        "In each of these examples, hypothesis testing provides a structured approach to assess claims or changes within different industries, helping decision-makers make informed choices based on statistical evidence."
      ],
      "metadata": {
        "id": "Nna-JxtN85x3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis Testing starts with the formulation of these two hypotheses:\n",
        "\n",
        "**Null hypothesis (H₀)**:  There is no significant difference between the observed sample and the general population or between two samples.\n",
        "\n",
        "**Alternate hypothesis (H₁)**: Claims there is some statistical significance between two variables."
      ],
      "metadata": {
        "id": "4ctV0BVz9iRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the hypothesis is often complicated so we can follow these rules to correctly formulate both the hypotheses.\n",
        "\n",
        "The null hypothesis always has the following signs:  `=  OR   ≤   OR    ≥`\n",
        "\n",
        "The alternate hypothesis always has the following signs:  `≠   OR  >   OR    <`"
      ],
      "metadata": {
        "id": "ttRd66VM9qGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1**:  Zomato claimed that its total valuation in December 2023 was at least $500 million. Here, the claim contains ≥ sign (i.e. the at least sign), so the null hypothesis is the original claim.\n",
        "\n",
        "**Example 2**:  Zomato claimed that its total valuation in December 2023 was greater than $500 million. Here, the claim contains > sign (i.e. the ‘more than’ sign), so the null hypothesis is the complement of the original claim."
      ],
      "metadata": {
        "id": "1JCDgXBh-ctD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a Decision\n",
        "\n",
        "Once you have formulated the null and alternate hypotheses, we have to decide to either reject or fail to reject the null hypothesis.\n",
        "\n",
        "Let's say Maruti has to buy tires for it's cars from a tire manufacturer. The tire manufacture claims that life of their tire is 36 months. Now we have to find out whether they are correct or not.\n",
        "\n",
        "- Null hypothesis (H₀) : Life of tire = 36 months\n",
        "- Alternate hypothesis (H₁) : Life of tire != 36 months\n",
        "\n",
        "Now Maruti tests 100 tires and the average comes to be 32 months. So do we accept their claim or reject it. If average comes 28 months then what?\n",
        "\n",
        "For this case we define critical region. Upper and lower critical region. If the average is less than lower critical value and more than upper critical value then we reject the null hypothesis."
      ],
      "metadata": {
        "id": "w681X9Ui_TkF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The formulation of the null and alternate hypotheses determines the type of the test and the position of the critical regions in the normal distribution.\n",
        "\n",
        "You can tell the type of the test and the position of the critical region on the basis of the ‘sign’ in the alternate hypothesis.\n",
        "\n",
        "       ≠ in H₁    →   Two-tailed test        →     Rejection region on both sides of distribution\n",
        "       < in H₁    →   Lower-tailed test     →     Rejection region on left side of distribution\n",
        "       > in H₁    →   Upper-tailed test     →     Rejection region on right side of distribution"
      ],
      "metadata": {
        "id": "ea-wzHxi_nvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps to perform Hypothesis Testing:"
      ],
      "metadata": {
        "id": "Q4XEzl38AmLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Formulate the Hypotheses**\n",
        "The first step is to clearly define the null hypothesis (H₀) and the alternative hypothesis (H₁).\n",
        "    - `Null Hypothesis (H₀)`: There is no significant difference between the observed sample and the general population or between two samples.\n",
        "    - `Alternative Hypothesis (H₁)`: There is a significant difference or effect that is not due to chance alone.\n",
        "\n",
        "\n",
        "2. **Select the Significance Level (α)**\n",
        "The significance level (α) is the probability of rejecting the null hypothesis when it is actually true (Type I error). Commonly used α levels are 0.05 (5%) or 0.01 (1%).\n",
        "\n",
        "\n",
        "3. **Collect and Analyze Data**\n",
        "Data collection can be done through random sampling or experimental design. The data must be relevant to the hypotheses and collected in a way that minimizes bias. Once collected, the data is analyzed to summarize its main characteristics, often through descriptive statistics or visualizations.\n",
        "\n",
        "\n",
        "\n",
        "4. **Calculate the Test Statistic**\n",
        "The test statistic is a numerical value calculated from the sample data that, under the null hypothesis, follows a known distribution. The choice of test statistic depends on the nature of the data and the hypothesis being tested. Common tests include t-tests, z-tests, chi-square tests, and ANOVA, among others.\n",
        "\n",
        "\n",
        "5. **Determine the Critical Region or Calculate the P-value**\n",
        "    - `Critical Region`: This approach involves comparing the test statistic to critical values that define regions where the null hypothesis would be rejected. The critical values are determined based on the significance level and the distribution of the test statistic.\n",
        "    - `P-value`: Alternatively, the p-value approach calculates the probability of observing a test statistic as extreme as, or more extreme than, the value calculated from the sample data, assuming the null hypothesis is true. If the p-value is less than or equal to the significance level (α), the null hypothesis is rejected.\n",
        "    - **We prefer using the p-value method over the critical-region method.**\n",
        "\n",
        "6. **Make a Decision**\n",
        "    - If the test statistic falls within the critical region or the p-value is less than or equal to α, reject the null hypothesis in favor of the alternative hypothesis.\n",
        "    - If the test statistic does not fall within the critical region or the p-value is greater than α, do not reject the null hypothesis.\n",
        "\n",
        "\n",
        "7. **Draw Conclusions**\n",
        "Finally, interpret the results in the context of the original research question or business problem. This involves stating whether the findings support the alternative hypothesis and discussing the implications of the results for the problem at hand."
      ],
      "metadata": {
        "id": "KmiM7d_9_spb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Z-Test**\n",
        "\n",
        "A z-test is a statistical method used in hypothesis testing to determine if there is a significant difference between sample and population means, or between the means of two samples. It is particularly useful when the population standard deviation is known and the sample size is large (typically greater than 30).\n",
        "\n",
        "`We have mainly two types of z-test:`\n",
        "\n",
        "1. **One-Sample Z-Test:** Used to determine whether the mean of a single sample is different from a known population mean.\n",
        "2. **Two-Sample Z-Test:** Used to compare the means of two independent samples to see if they are significantly different from each other.\n",
        "\n",
        "**Assumptions of Z-Tests**\n",
        "\n",
        "For a z-test to yield valid/correct results, these assumptions must be met:\n",
        "1. **Normal Distribution:** The data should be approximately normally distributed. This assumption is satisfied with large sample sizes due to the central limit theorem.\n",
        "2. **Known Population Standard Deviation:** The standard deviation of the population must be known. If it is unknown, using a `t-test` is more appropriate.\n",
        "3. **Random Sampling:** The sample data should be randomly drawn from the population, ensuring that it is representative of the actual population data.\n",
        "4. **Independence:** The samples must be independent of each other, particularly in two-sample z-tests.\n",
        "5. **Continuous Data:** The z-test is applicable for continuous data, where the variable of interest can take any numeric value."
      ],
      "metadata": {
        "id": "wr7Ev8aeAI5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Z-Test Example"
      ],
      "metadata": {
        "id": "EJXJqlXMBLIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1:** Google claims that its internet browser ‘Chrome’ is the best in the industry, as it has an optimum boot time of only 250 ms, with a standard deviation of 9 ms. Sam, a tech geek, wanted to test the claim of Google. So, he randomly collected boot time data of 165 devices of Chrome and got a sample mean of 247 ms.\n",
        "\n",
        "- Ho: μ = 250, i.e., the mean boot time is 250 ms.\n",
        "- Ha: μ ≠ 250, i.e., the mean boot time is not 250 ms."
      ],
      "metadata": {
        "id": "yFVOnME-BWwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Solution using Critical Region/Value method**"
      ],
      "metadata": {
        "id": "sNDmWM0VBa_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Z-Test these two conditions should be met:\n",
        "\n",
        "- Condition 1: n >30, which means that the population sample size should be greater than 30 observations.\n",
        "\n",
        "- Condition 2: 𝝈 is known, i.e., the population standard deviation is known.\n",
        "\n",
        "If any of these conditions are not met then `we use t-test`.\n",
        "\n",
        "The next step is to determine the test statistic. A test statistic, in simple terms, is a value that is to be calculated from some given data, which is then used to compare the results arrived at with the tabular values.\n",
        "\n",
        "The test statistic for a normal distribution or a Z-test is defined as:\n",
        "\n",
        "`Z = x−μ / σ/√n`\n",
        "\n",
        "x is the process mean, μ is the population mean, σ is the standard deviation and n is the sample size.\n",
        "\n",
        "Z = (247 - 250)/(9/√165)\n",
        "Z = -4.3\n",
        "\n",
        "We will now test our hypothesis at a 95% confidence level. For a 95% confidence interval, Z critical value = +1.96 and -1.96; these are the upper and lower critical values, respectively. The test statistic value we calculated is -4.3.\n",
        "\n",
        "The region between +1.96 and -1.96 is called the acceptance region, and the region outside it is called the critical region.\n",
        "\n",
        "If the calculated Z-statistic is in the region of acceptance, you fail to reject the null hypothesis. If the calculated Z-statistic lies outside the region of acceptance, i.e., in the critical region, you reject the null hypothesis.\n",
        "\n",
        "In our case, the test statistic value is -4.3, which lies outside the region of acceptance of ±1.96. So, you reject the null hypothesis."
      ],
      "metadata": {
        "id": "Py7UDBduBf4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Solution of Example 1 using p_value method which is very easy and straightforward.**"
      ],
      "metadata": {
        "id": "X_3jzNV0BwGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.weightstats import ztest\n",
        "import numpy as np\n",
        "\n",
        "boot_times = list(np.random.randint(200, 270, size = 165))  #generating a list of 165 random integers between 180 and 300\n",
        "\n",
        "# Perform one-sample Z-test\n",
        "z_statistic, p_value = ztest(boot_times, value=250)   #here the value parameter is the population mean\n",
        "\n",
        "# Interpret the results\n",
        "if p_value < 0.025:\n",
        "    print(f\"Z-statistic: {z_statistic:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We have sufficient evidence to reject the null hypothesis.\")\n",
        "else:\n",
        "    print(f\"Z-statistic: {z_statistic:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We do not have sufficient evidence to reject the null hypothesis.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzIHkx3YA39A",
        "outputId": "526e5709-a238-4b5d-a994-dbb3e208abf0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z-statistic: -11.1823, p-value: 0.0000\n",
            "We have sufficient evidence to reject the null hypothesis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The code in above cell in not complete because while performing Z-test we should know the population standard deviation and utilize it in the code of z-test. So let's add that part of using population standard deviation and make it complete."
      ],
      "metadata": {
        "id": "j9PogU90Fyuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.weightstats import ztest\n",
        "import numpy as np\n",
        "\n",
        "boot_times = list(np.random.randint(180, 300, size = 165))  #generating a list of 165 random integers between 180 and 300\n",
        "\n",
        "population_mean = 250\n",
        "pop_std_dev = 9\n",
        "\n",
        "standardized_boot_times = [(x - population_mean) / (pop_std_dev/np.sqrt(len(boot_times))) for x in boot_times]\n",
        "\n",
        "# Perform one-sample Z-test\n",
        "z_statistic, p_value = ztest(standardized_boot_times, value=0)  #here value = 250 but after standardization we always write value = 0\n",
        "\n",
        "# Interpret the results\n",
        "if p_value < 0.05:\n",
        "    print(f\"Z-statistic: {z_statistic:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We have sufficient evidence to reject the null hypothesis.\")\n",
        "else:\n",
        "    print(f\"Z-statistic: {z_statistic:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We do not have sufficient evidence to reject the null hypothesis.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ddAX7Ct9-eD",
        "outputId": "b657b39a-c68c-465c-d87c-37c12b3875a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z-statistic: -3.0306, p-value: 0.0024\n",
            "We have sufficient evidence to reject the null hypothesis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose a company is evaluating the impact of a new training program on the productivity of its employees. The company has data on the average productivity of its employees before implementing the new training program. The average productivity was 50 units per day with a known pop standard deviation of 5 units. After implementing the training program, the company measures the productivity of a random sample of 30 employees. The sample employees have an average productivity of 53 units per day. The company wants to know if the new training program has significantly improved the productivity of the employees."
      ],
      "metadata": {
        "id": "Ok-7sC9nGI18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from statsmodels.stats.weightstats import ztest\n",
        "\n",
        "sample_data = list(np.random.randint(50, 59, size = 30))\n",
        "\n",
        "pm = 50\n",
        "pop_std_dev = 5\n",
        "\n",
        "standardized_sample_data = [(x - pm) / (pop_std_dev / np.sqrt(len(sample_data))) for x in sample_data]\n",
        "\n",
        "z_statistic, p_value = ztest(standardized_sample_data, value = 0)"
      ],
      "metadata": {
        "id": "xgtgu9v4BWQA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_statistic, p_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ-S7Xh69Gdp",
        "outputId": "59963d7e-956f-4400-e9ba-e3193f872e7e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(6.984328542534465), np.float64(2.8622155375075756e-12))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC3E8_YF8MVu",
        "outputId": "1fbf322b-9d8d-4341-ba94-a3257e2be6e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.int64(56),\n",
              " np.int64(51),\n",
              " np.int64(52),\n",
              " np.int64(51),\n",
              " np.int64(53),\n",
              " np.int64(54),\n",
              " np.int64(53),\n",
              " np.int64(55),\n",
              " np.int64(53),\n",
              " np.int64(55),\n",
              " np.int64(51),\n",
              " np.int64(50),\n",
              " np.int64(58),\n",
              " np.int64(57),\n",
              " np.int64(54),\n",
              " np.int64(50),\n",
              " np.int64(53),\n",
              " np.int64(53),\n",
              " np.int64(52),\n",
              " np.int64(50),\n",
              " np.int64(52),\n",
              " np.int64(50),\n",
              " np.int64(54),\n",
              " np.int64(52),\n",
              " np.int64(51),\n",
              " np.int64(58),\n",
              " np.int64(51),\n",
              " np.int64(52),\n",
              " np.int64(56),\n",
              " np.int64(52)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### T-test\n",
        "\n",
        "The t-distribution is kind of a normal distribution; it is also symmetric and single peaked but less concentrated around its peak. In layman’s terms, a t-distribution is shorter and flatter around the centre than a normal distribution. It is used to study the mean of a population that has a distribution fairly close to a normal distribution (but not an exact normal distribution).\n",
        "\n",
        "**Two simple conditions to determine when to use the t-statistic are as follows:**\n",
        "\n",
        "- The population standard deviation is unknown.\n",
        "- The sample size is less than 30.\n",
        "\n",
        "Even if one of them is applicable in a situation, you can comfortably go for a t-test. The formula to determine the t-statistic is:\n",
        "\n",
        "                            t = x–μ / s/√n\n"
      ],
      "metadata": {
        "id": "iAkJyYE2Gqky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The company claims that their new algorithm can process a specific dataset in an average of 20 minutes, which is faster than the current average processing time of 22 minutes using the standard algorithm. To validate this claim, a data scientist decides to conduct a t-test.\n",
        "The data scientist collects a sample of processing times using the new algorithm. The sample consists of 10 processing times (in minutes):\n",
        "\n",
        "Sample Data : 19,18,21,20,19,22,18,17,21,20\n",
        "\n",
        "The data scientist wants to test if the new algorithm significantly reduces the processing time compared to the standard average of 22 minutes. The hypothesis for the t-test would be set up as follows:\n",
        "- `Null Hypothesis (H₀)`: The mean processing time using the new algorithm is equal to 22 minutes. (μ≥22)\n",
        "- `Alternative Hypothesis (H₁)`: The mean processing time using the new algorithm is less than 22 minutes. (μ<22)"
      ],
      "metadata": {
        "id": "gDZyItB4G48D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **One-Sample t-test**"
      ],
      "metadata": {
        "id": "g7R6Ko9wG-Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "global_average_score = 22\n",
        "sample_scores = [19,18,21,20,19,22,18,17,21,20]\n",
        "\n",
        "t_stat, p_value = ttest_1samp(sample_scores, global_average_score)"
      ],
      "metadata": {
        "id": "3Fb5xmx-GvFJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hzFmym4vHkfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "pm = 22\n",
        "\n",
        "sample_data = [19,18,21,20,19,22,18,17,21,20]\n",
        "\n",
        "t_statistic, p_value = ttest_1samp(sample_data, pm)"
      ],
      "metadata": {
        "id": "KfUp_TdRHTB0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul1uYRSwHoAn",
        "outputId": "45b01e52-9c00-4cc2-db33-dc9dddf62757"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.0007389679098032424)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result of the t-test indicates that there is significant evidence to conclude that the new algorithm reduces the processing time for processing the datasets compared to the standard processing time of 22 minutes. Therefore, we can confidently claim that the new algorithm is more efficient."
      ],
      "metadata": {
        "id": "kYFTQtZgHv9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement : Suppose a manufacturer claims that the average protein content in their new chocolate bars is 50 grams, which we highly doubt and want to check this. So we drew out a sample of 25 chocolate bars and measured their protein content, the sample mean came out to be 49.7 grams and the sample standard deviation was 1.2 grams. Consider the significance level to be 0.05."
      ],
      "metadata": {
        "id": "dliJXMTlHyjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Two-Sample t-test**\n",
        "\n",
        "A two-sample t-test is often used to determine if there is a significant difference between the means of two groups."
      ],
      "metadata": {
        "id": "-An4VYkVIEMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A researcher wants to evaluate whether there is a significant difference in the average test scores of students who used two different study methods (Method A and Method B) for an exam. The researcher randomly selects two independent groups of students: one group uses Method A, and the other uses Method B. The test scores for each group are recorded as follows:\n",
        "\n",
        "- Method A Scores: [78, 84, 92, 88, 75, 80, 85, 90, 87, 79]\n",
        "- Method B Scores: [82, 88, 75, 90, 78, 85, 88, 77, 92, 80]"
      ],
      "metadata": {
        "id": "kD_hN1-7IGSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Sample data for Method A and Method B\n",
        "method_a_scores = np.array([78, 84, 92, 88, 75, 80, 85, 90, 87, 79])\n",
        "method_b_scores = np.array([82, 88, 75, 90, 78, 85, 88, 77, 92, 80])\n",
        "\n",
        "# Step 1: Perform Shapiro-Wilk test for normality\n",
        "shapiro_a = stats.shapiro(method_a_scores)\n",
        "shapiro_b = stats.shapiro(method_b_scores)\n",
        "\n",
        "print(\"Shapiro-Wilk Test for Method A: Statistic =\", shapiro_a.statistic, \", p-value =\", shapiro_a.pvalue)\n",
        "print(\"Shapiro-Wilk Test for Method B: Statistic =\", shapiro_b.statistic, \", p-value =\", shapiro_b.pvalue)\n",
        "\n",
        "# Step 2: Perform Levene's test for equal variances\n",
        "levene_test = stats.levene(method_a_scores, method_b_scores)\n",
        "print(\"Levene's Test: Statistic =\", levene_test.statistic, \", p-value =\", levene_test.pvalue)\n",
        "\n",
        "# Step 3: Perform independent two-sample t-test\n",
        "t_statistic, p_value = stats.ttest_ind(method_a_scores, method_b_scores)\n",
        "\n",
        "# Step 4: Print results\n",
        "alpha = 0.05\n",
        "print(\"T-statistic:\", t_statistic)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Decision based on p-value\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in average scores.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference in average scores.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwDF9nbFITSx",
        "outputId": "07d35686-ce6e-4f2a-b5df-a279806f2ad3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapiro-Wilk Test for Method A: Statistic = 0.9634209538811345 , p-value = 0.8240632802317183\n",
            "Shapiro-Wilk Test for Method B: Statistic = 0.9429848795756282 , p-value = 0.5866793733496176\n",
            "Levene's Test: Statistic = 0.16879219804951237 , p-value = 0.6860370886859155\n",
            "T-statistic: 0.11617981913799512\n",
            "P-value: 0.9087964141018375\n",
            "Fail to reject the null hypothesis: No significant difference in average scores.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Sample data for Method A and Method B\n",
        "method_a_scores = np.array([78, 84, 92, 88, 75, 80, 85, 90, 87, 79])\n",
        "method_b_scores = np.array([82, 88, 75, 90, 78, 85, 88, 77, 92, 80])\n",
        "\n",
        "# Step 1: Perform Shapiro-Wilk test for normality\n",
        "shapiro_a = stats.shapiro(method_a_scores)\n",
        "shapiro_b = stats.shapiro(method_b_scores)\n",
        "\n",
        "print(shapiro_a.pvalue)\n",
        "print(shapiro_b.pvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8B1VKEWIg9_",
        "outputId": "e258e7fd-388c-4259-d95c-1e50d1be7c13"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8240632802317183\n",
            "0.5866793733496176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "levene_test = stats.levene(method_a_scores, method_b_scores)\n",
        "print(levene_test.pvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE5lK1TGIl0A",
        "outputId": "7433e256-cf25-4ad8-820a-724f70a0b8fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6860370886859155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a3VIF_HsIK43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_statistic, p_value = stats.ttest_ind(method_a_scores, method_b_scores)\n",
        "\n",
        "print(p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21wVPVZDHsXl",
        "outputId": "5af18643-5e23-4eed-aea1-5e6ef8f4d431"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9087964141018375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 2: Let's consider a scenario where a company wants to test if a new training program improves employee productivity. The productivity scores (measured in units of work completed per day) of employees who underwent the training are compared to those who did not.\n",
        "\n",
        "**Hypothesis**\n",
        "- Null Hypothesis (): There is no difference in productivity between trained and untrained employees.\n",
        "- Alternative Hypothesis (): There is a difference in productivity between trained and untrained employees."
      ],
      "metadata": {
        "id": "XLEb0wPwIyH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Generating synthetic productivity data for trained employees\n",
        "np.random.seed(0)  # for reproducibility of the random values being generate by the following random.normal functions\n",
        "trained_productivity = np.random.normal(loc=80, scale=10, size=40)  # Mean 80, std dev 10\n",
        "\n",
        "# Generating synthetic productivity data for untrained employees\n",
        "untrained_productivity = np.random.normal(loc=75, scale=10, size=40)  # Mean 75, std dev 10\n",
        "\n",
        "# Performing a two-sample t-test on the productivity data\n",
        "t_statistic, p_value = ttest_ind(trained_productivity, untrained_productivity, equal_var = False)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.025\n",
        "if p_value < alpha:\n",
        "    print(f\"T-statistic: {t_statistic:.4f}, p-value: {p_value:.9f}\")\n",
        "    print(\"We have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is a significant difference in productivity between trained and untrained employees.\")\n",
        "else:\n",
        "    print(f\"T-statistic: {t_statistic:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We do not have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is no significant difference in productivity between trained and untrained employees.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgxL6PzmI3_A",
        "outputId": "a2cae04f-0e32-4d4a-bc05-45a2231d4398"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-statistic: 5.5380, p-value: 0.000000460\n",
            "We have sufficient evidence to reject the null hypothesis.\n",
            "There is a significant difference in productivity between trained and untrained employees.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python code uses the ttest_ind function from the scipy.stats module to perform a two-sample t-test assuming unequal variances (Welch's t-test). The equal_var=False parameter is set to handle cases where the two groups have different variances."
      ],
      "metadata": {
        "id": "naMogbg8JG2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement 3:**\n",
        "\n",
        "A retail company wants to evaluate the effectiveness of two different marketing strategies on sales performance. They implement Strategy A in one region and Strategy B in another region. After a month, they collect sales data from both regions. The company wants to determine if there is a statistically significant difference in the average sales between the two regions.\n",
        "\n",
        "**Hypothesis Statements:**\n",
        "- Null Hypothesis ($H_0$): There is no difference in the average sales between the two marketing strategies. ($\\mu_{\\text{A}} = \\mu_{\\text{B}}$)\n",
        "- Alternative Hypothesis ($H_1$): There is a difference in the average sales between the two marketing strategies. ($\\mu_{\\text{A}} \\neq \\mu_{\\text{B}}$)"
      ],
      "metadata": {
        "id": "AZkQcy48JQNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Sample data: sales in thousands of dollars\n",
        "sales_strategy_A = np.random.normal(loc=100, scale=15, size=50)  # Mean 100, std dev 15\n",
        "sales_strategy_B = np.random.normal(loc=110, scale=15, size=50)  # Mean 110, std dev 15\n",
        "\n",
        "# Perform two-sample t-test\n",
        "t_statistic, p_value = ttest_ind(sales_strategy_A, sales_strategy_B)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"T-statistic: {t_statistic:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is a significant difference in average sales between the two marketing strategies.\")\n",
        "else:\n",
        "    print(f\"T-statistic: {t_statistic:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We do not have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is no significant difference in average sales between the two marketing strategies.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI7N1Z9BJMFp",
        "outputId": "1a30f1a9-9dd3-475f-a985-e7054036bebb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-statistic: -1.0967, p-value: 0.2755\n",
            "We do not have sufficient evidence to reject the null hypothesis.\n",
            "There is no significant difference in average sales between the two marketing strategies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Another Example of two sample t-test\n",
        "\n",
        "\n",
        "A dataset from a recent health survey that includes information on participants' gender (male or female) and their cholesterol levels (a quantitative variable). The data scientist wants to investigate whether there is a significant difference in the mean cholesterol levels between male and female participants."
      ],
      "metadata": {
        "id": "DTzRE3VgJfqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "gender = np.array([\"Male\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", \"Male\",\n",
        "                   \"Female\", \"Male\", \"Female\"])\n",
        "\n",
        "cholesterol = np.array([200, 220, 210, 190, 205, 195, 180, 230, 175, 225])\n",
        "\n",
        "# Since the gender array contains categorical data, we need to separate the cholesterol data by gender\n",
        "male_cholesterol = cholesterol[gender == \"Male\"]\n",
        "female_cholesterol = cholesterol[gender == \"Female\"]\n",
        "\n",
        "# Perform the two-sample t-test\n",
        "t_stat, p_value = stats.ttest_ind(male_cholesterol, female_cholesterol)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR4ILX7cJqsU",
        "outputId": "b484472a-4c07-49cd-c756-c60e31c6b352"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-statistic: -4.57495710997814\n",
            "P-value: 0.0018139585097282133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `ttest_ind` function is used to compare the means of two independent samples, which in this case are the cholesterol levels of males and females. The gender array is used to filter the cholesterol array into two groups: male_cholesterol and female_cholesterol."
      ],
      "metadata": {
        "id": "n-Aj37vFJ2Nt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chi-Squared Test\n",
        "\n",
        "A Chi-Squared test is a statistical method used in hypothesis testing to determine if there is a significant difference between observed and expected frequencies in one or more categories. It is particularly useful for analyzing categorical data and is often employed to test relationships between categorical variables.\n",
        "\n",
        "**Chi-squared test of independence**: This is used to determine whether or not there is a significant relationship between two nominal (categorical) variables."
      ],
      "metadata": {
        "id": "aJITiFy0J5Dr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement:**\n",
        "\n",
        "A marketing team at a software company wants to determine if there is a relationship between the type of advertising medium (online, print, television) and software purchases. They collect data from a sample of customers, noting the advertising medium each customer was exposed to and whether they purchased the software.\n",
        "\n",
        "**Hypotheses:**\n",
        "\n",
        "- Null Hypothesis ($H_0$): There is no association between the type of advertising medium and software purchases. The variables are independent.\n",
        "- Alternative Hypothesis ($H_1$): There is an association between the type of advertising medium and software purchases. The variables are not independent."
      ],
      "metadata": {
        "id": "1b7ZOhh8J_Pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Observed frequency data in a contingency table\n",
        "# Rows in the data array represent: Advertising Medium (Online, Print, Television)\n",
        "# Columns in the data array represent: Purchase (Yes, No)\n",
        "data = np.array([[30, 10],  # Online\n",
        "                 [20, 20],  # Print\n",
        "                 [50, 30]]) # Television\n",
        "\n",
        "# Perform Chi-Square Test of Independence\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"Chi-Square Statistic: {chi2_stat:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is a significant association between the advertising medium and software purchases.\")\n",
        "else:\n",
        "    print(f\"Chi-Square Statistic: {chi2_stat:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We do not have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is no significant association between the advertising medium and software purchases.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge0d4EeoJ-QW",
        "outputId": "2f6c8c22-ed3a-4d23-f995-0f4b578a7c72"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-Square Statistic: 5.3333, p-value: 0.0695\n",
            "We do not have sufficient evidence to reject the null hypothesis.\n",
            "There is no significant association between the advertising medium and software purchases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement 2:**\n",
        "A restaurant chain wants to determine if there is an association between the type of cuisine offered (Italian, Chinese, Mexican) and customer satisfaction levels (satisfied, neutral, dissatisfied). They conduct a survey among customers across several locations to collect this data.\n",
        "\n",
        "**Hypotheses:**\n",
        "- Null Hypothesis ($H_0$): There is no association between the type of cuisine and customer satisfaction levels. The variables are independent.\n",
        "- Alternative Hypothesis ($H_1$): There is an association between the type of cuisine and customer satisfaction levels. The variables are not independent."
      ],
      "metadata": {
        "id": "hStzwHJpKTHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Observed frequency data in a contingency table\n",
        "# Rows: Type of Cuisine (Italian, Chinese, Mexican)\n",
        "# Columns: Customer Satisfaction (Satisfied, Neutral, Dissatisfied)\n",
        "data = np.array([[40, 30, 10],  # Italian\n",
        "                 [35, 25, 20],  # Chinese\n",
        "                 [25, 30, 15]]) # Mexican\n",
        "\n",
        "# Perform Chi-Square Test of Independence\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"Chi-Square Statistic: {chi2_stat:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is a significant association between the type of cuisine and customer satisfaction levels.\")\n",
        "else:\n",
        "    print(f\"Chi-Square Statistic: {chi2_stat:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We do not have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is no significant association between the type of cuisine and customer satisfaction levels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npGaa6P7JyBv",
        "outputId": "2b464e9c-f891-4b22-a1cc-dc05b66affaf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-Square Statistic: 6.4983, p-value: 0.1649\n",
            "We do not have sufficient evidence to reject the null hypothesis.\n",
            "There is no significant association between the type of cuisine and customer satisfaction levels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, a Chi-Square test evaluates whether the observed contingency table is significantly different from the table that would be expected if there were no association between the variables."
      ],
      "metadata": {
        "id": "LhaIu76iKybs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chi-Squared Goodness of fit"
      ],
      "metadata": {
        "id": "lkmqiCnJK67R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A game manufacturer wants to test if a six-sided die is fair. The die is rolled 60 times, and the observed frequencies for each face are: [10, 8, 12, 11, 9, 10]. Assuming a fair die, each face should appear equally often (expected frequency = 10 for each face)."
      ],
      "metadata": {
        "id": "t8Us1r6dK8e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "observed = np.array([10, 8, 12, 11, 9, 10])\n",
        "expected = np.array([10, 10, 10, 10, 10, 10])\n",
        "\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "print(\"Chi-squared Statistic:\", chi2_stat)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crF-B4NAK2PU",
        "outputId": "7453742f-fa0b-404a-8860-c6f991cfb08d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-squared Statistic: 1.0\n",
            "P-value: 0.9625657732472964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A shop owner claims that an equal number of customers visit their shop on each weekday. To test this claim, the owner records the number of customers over a week: [50 (Monday), 60 (Tuesday), 40 (Wednesday), 47 (Thursday), and 53 (Friday)]. The expected frequency for each day is\n",
        "total customers =50."
      ],
      "metadata": {
        "id": "Ihk58BDQLHYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Observed and expected frequencies\n",
        "observed_customers = np.array([50, 60, 40, 47, 53])\n",
        "expected_customers = np.array([50, 50, 50, 50, 50])\n",
        "\n",
        "# Perform Chi-Squared Goodness of Fit test\n",
        "chi2_stat_customers, p_value_customers = chisquare(f_obs=observed_customers, f_exp=expected_customers)\n",
        "\n",
        "print(\"Chi-squared Statistic:\", chi2_stat_customers)\n",
        "print(\"P-value:\", p_value_customers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6Lmv3dALNdJ",
        "outputId": "b5bb870e-32bc-4312-d1c1-f9d3162dd1c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-squared Statistic: 4.359999999999999\n",
            "P-value: 0.3594720674366307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A candy company claims that all four flavors in their product are equally distributed. A sample of candies yields these counts: [22 (Flavor A), 30 (Flavor B), 23 (Flavor C), and 25 (Flavor D)]. The expected frequency for each flavor is 25."
      ],
      "metadata": {
        "id": "jT1nUr42LWch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observed_candies = np.array([22, 30, 23, 25])\n",
        "expected_candies = np.array([25, 25, 25, 25])\n",
        "\n",
        "chi2_stat_candies, p_value_candies = chisquare(f_obs=observed_candies, f_exp=expected_candies)\n",
        "print(\"Chi-squared Statistic:\", chi2_stat_candies)\n",
        "print(\"P-value:\", p_value_candies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEgqxpXQLYx1",
        "outputId": "b75f8342-0053-4870-e59d-51a59d7ac09d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-squared Statistic: 1.5199999999999998\n",
            "P-value: 0.6776620931894994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ANOVA (Analysis of Variance)**"
      ],
      "metadata": {
        "id": "p6cGvcSYLj-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of Variance (ANOVA) is a statistical method used to compare the means of three or more groups to determine if there are any statistically significant differences between them. It helps to identify whether the observed differences among group means are due to actual differences or random chance.\n",
        "`ANOVA uses F-tests` to statistically test the equality of means.\n",
        "\n",
        "Two sample t-tests can validate a hypothesis containing only two groups at a time. For samples involving three or more groups, the t-test becomes tedious, as you have to perform the tests for each combination of the groups. Also, the `possibility of a type-1 error increases` in this process."
      ],
      "metadata": {
        "id": "jxOBgGc9Lp8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-Way ANOVA**\n",
        "\n",
        "A One-Way ANOVA is used to determine whether there are statistically significant differences between the means of three or more independent groups. For the results of a One-Way ANOVA to be valid, certain assumptions must be met:\n",
        "1. `Independence of Observations:` The observations in each group must be independent of each other. This means that the data collected from one group should not influence the data collected from another group.\n",
        "2. `Normality:` The data within each group should be approximately normally distributed. This assumption is particularly important when the sample sizes are small, as ANOVA is robust to deviations from normality with larger sample sizes.\n",
        "3. `Homogeneity of Variances:` The variances among the different groups should be approximately equal. This can be tested using **Levene's test for homogeneity of variances**.\n",
        "4. `Continuous Dependent Variable:` The dependent variable should be measured on a continuous scale."
      ],
      "metadata": {
        "id": "QcygSpmdL1yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement:** A researcher wants to investigate whether different diets lead to different weight loss outcomes. Three different diet plans (Diet A, Diet B, and Diet C) are tested on groups of participants, and the weight loss (in kilograms) is recorded after a month. The researcher wants to determine if there is a significant difference in mean weight loss among the three diet plans.\n",
        "\n",
        "**Hypotheses:**\n",
        "- Null Hypothesis ($H_0$): There is no difference in the mean weight loss among the three diet plans. ($\\mu_A = \\mu_B = \\mu_C$)\n",
        "- Alternative Hypothesis ($H_1$): At least one diet plan has a different mean weight loss compared to the others."
      ],
      "metadata": {
        "id": "T4y_FzHkL-n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f_oneway, levene\n",
        "\n",
        "# Sample data: weight loss for each diet plan\n",
        "diet_A_loss = np.random.normal(loc=5, scale=1.5, size=30)  # Mean 5 kg, std dev 1.5\n",
        "diet_B_loss = np.random.normal(loc=6, scale=1.5, size=30)  # Mean 6 kg, std dev 1.5\n",
        "diet_C_loss = np.random.normal(loc=4.5, scale=1.5, size=30)  # Mean 4.5 kg, std dev 1.5\n",
        "\n",
        "# Perform Levene's Test for equal variances\n",
        "levene_stat, levene_p_value = levene(diet_A_loss, diet_B_loss, diet_C_loss)\n",
        "\n",
        "# Interpret Levene's Test results\n",
        "alpha = 0.05\n",
        "if levene_p_value < alpha:\n",
        "    print(f\"Levene's Test p-value: {levene_p_value:.4f}\")\n",
        "    print(\"The variances are significantly different. Consider using a different test for ANOVA.\")\n",
        "else:\n",
        "    print(f\"Levene's Test p-value: {levene_p_value:.4f}\")\n",
        "    print(\"The variances are not significantly different. Proceeding with ANOVA.\")\n",
        "\n",
        "# Perform One-Way ANOVA\n",
        "anova_stat, anova_p_value = f_oneway(diet_A_loss, diet_B_loss, diet_C_loss)\n",
        "\n",
        "# Interpret ANOVA results\n",
        "if anova_p_value < alpha:\n",
        "    print(f\"ANOVA p-value: {anova_p_value:.4f}\")\n",
        "    print(\"We have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is a significant difference in mean weight loss among the diet plans.\")\n",
        "else:\n",
        "    print(f\"ANOVA p-value: {anova_p_value:.4f}\")\n",
        "    print(\"We do not have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is no significant difference in mean weight loss among the diet plans.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uXbskwJMDHb",
        "outputId": "f4b7c795-74cb-4c33-93f3-cd2bb53b002a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Levene's Test p-value: 0.4653\n",
            "The variances are not significantly different. Proceeding with ANOVA.\n",
            "ANOVA p-value: 0.0000\n",
            "We have sufficient evidence to reject the null hypothesis.\n",
            "There is a significant difference in mean weight loss among the diet plans.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rEfbGzywNOiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f_oneway, levene\n",
        "\n",
        "# Sample data: weight loss for each diet plan\n",
        "diet_A_loss = np.random.normal(loc=5, scale=1.5, size=30)  # Mean 5 kg, std dev 1.5\n",
        "diet_B_loss = np.random.normal(loc=6, scale=1.5, size=30)  # Mean 6 kg, std dev 1.5\n",
        "diet_C_loss = np.random.normal(loc=4.5, scale=1.5, size=30)  # Mean 4.5 kg, std dev 1.5\n",
        "\n",
        "#step 1: shapiro wilk test to perform nomality\n",
        "shapiro_a = stats.shapiro(diet_A_loss)\n",
        "shapiro_b = stats.shapiro(diet_B_loss)\n",
        "shapiro_c = stats.shapiro(diet_C_loss)\n",
        "\n",
        "print(shapiro_a.pvalue)\n",
        "print(shapiro_b.pvalue)\n",
        "print(shapiro_c.pvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfTPvHqwNOSE",
        "outputId": "bd411625-f2b3-4517-d0fb-f8a0d12ef75d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7203177602421449\n",
            "0.9624176708216704\n",
            "0.5935965401670127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##perform levene test for equqal variace\n",
        "levene_stat, levene_p_value = levene(diet_A_loss, diet_B_loss, diet_C_loss)\n",
        "print(levene_stat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlIFHQRiPFxa",
        "outputId": "dd60ea6b-4665-4359-abf7-c3491b3a4728"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03465251345678155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(levene_p_value)##important cosideration point, so we have the same variances here because leven p values >0.05\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD5Gg1INPbh7",
        "outputId": "4f39a15a-bf29-4234-bedd-12c5378bb210"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9659543346349586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform One-Way ANOVA\n",
        "anova_stat, anova_p_value = f_oneway(diet_A_loss, diet_B_loss, diet_C_loss)\n",
        "print(anova_stat)\n",
        "print(anova_p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVPA3pLMRWAQ",
        "outputId": "51719dad-9ee0-4c6e-e10c-9055276bc3da"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.786183153461138\n",
            "0.0007749366335931776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `f_oneway` calculates the `F-value and the P-value`. The `F-value is the test statistic`, and the P-value tells us whether the observed differences in means across the groups are statistically significant.\n",
        "\n",
        "Remember, ANOVA tells us if `there's at least one significant difference` but doesn't specify where it is. If the test is significant, you would typically `follow up with post-hoc tests` to find out which specific groups differ from each other."
      ],
      "metadata": {
        "id": "yOSNEzG4MUku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to choose the Hypothesis Test"
      ],
      "metadata": {
        "id": "gU05P1L_MW5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Frequently used hypothesis tests`**:\n",
        "\n",
        "1. **Z-Test**\n",
        "    - `Use When`: Comparing the mean of a sample to a known population mean when the population variance is known and the sample size is large (n > 30).\n",
        "    - `Example`: Testing if the average height of a sample of students is different from the known average height of the population.\n",
        "\n",
        "---\n",
        "\n",
        "2. **T-Test**\n",
        "    - `One-Sample T-Test`: Compare the sample mean to a known value.\n",
        "    - `Two-Sample T-Test`: Compare the means of two independent samples.\n",
        "    - `Paired T-Test`: Compare means from the same group at different times.\n",
        "    - `Use When`: The population variance is unknown and the sample size is small (n < 30).\n",
        "    - `Example`: Testing if the average test scores of two different classes are significantly different.\n",
        "\n",
        "---\n",
        "\n",
        "3. **ANOVA (Analysis of Variance)**\n",
        "    - `One-Way ANOVA`: Compare means of three or more independent groups.\n",
        "    - `Two-Way ANOVA`: Compare means with two independent variables.\n",
        "    - `Use When`: Comparing the means of three or more groups to see if at least one group mean is different.\n",
        "    - `Example`: Testing if different teaching methods result in different student performance.\n",
        "\n",
        "---\n",
        "\n",
        "4. **Chi-Square Test**\n",
        "    - `Chi-Square Goodness of Fit Test`: Determine if a sample matches a population.\n",
        "    - `Chi-Square Test of Independence`: Determine if two categorical variables are independent.\n",
        "    - `Use When`: Dealing with categorical data to test relationships between variables.\n",
        "    - `Example`: Testing if there is an association between gender and voting preference.\n",
        "\n",
        "---\n",
        "\n",
        "**`Other Tests`**:\n",
        "\n",
        "1. **Mann-Whitney U Test**:\n",
        "    - `Use When`: Comparing differences between two independent groups when the data is not normally distributed.\n",
        "    - `Example`: Testing if the distribution of scores differs between two different teaching methods.\n",
        "\n",
        "---\n",
        "\n",
        "2. **Wilcoxon Signed-Rank Test**:\n",
        "    - `When to use`: Compare the distributions of two related groups (e.g., before and after a treatment).\n",
        "    - `Description`: Tests if the distributions of two related groups are significantly different.\n",
        "    - `Example`: Testing if there is a difference in performance before and after a training program.\n",
        "\n",
        "---\n",
        "\n",
        "3. **Kruskal-Wallis H Test**:\n",
        "    - `When to use`: To test if the distributions of multiple groups are significantly different or Comparing more than two independent groups when the data is not normally distributed.\n",
        "    - `Example`: Testing if there are differences in customer satisfaction scores across multiple stores.\n",
        "\n",
        "---\n",
        "\n",
        "4. **Shapiro-Wilk Test or D'Agostino's K^2 Test or Anderson-Darling Test**:\n",
        "    - `When to use`: Check if the data follows a normal distribution.\n",
        "    - `Description`: Tests if the data is normally distributed.\n",
        "\n",
        "---\n",
        "\n",
        "5. **Augmented Dickey-Fuller Test or Kwiatkowski-Phillips-Schmidt-Shin (KPSS) Test**:\n",
        "    - `When to use`: Check if a time series is stationary.\n",
        "    - `Description`: Tests if a time series is stationary."
      ],
      "metadata": {
        "id": "NMz-501gMbCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important Note"
      ],
      "metadata": {
        "id": "e5buVP47MmDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beyond choosing a hypothesis test, it is important to understand whether the data you have meets the assumptions of the test you want to run. Each hypothesis test has a unique set of assumptions, however, there is one assumption that all hypothesis tests share: the data was randomly sampled from the population of interest.\n",
        "\n",
        "This is important because random sampling ensures that the sample is representative of the population in terms of observed (and unobserved) characteristics. Unfortunately, there may be situations where random sampling is impossible, but it is important to understand how this can bias results of a test.\n",
        "\n",
        "For example, let’s return to the example with the yogurt company “The Dairy Culture”. Let’s say the company had multiple factories, but the quality assurance team only collected yogurts from one specific factory. The data is thus not randomly sampled from the entire population that we care about (all factories), and could be biased if the quality of yogurt differs at each one.\n",
        "\n",
        "There can also be ethical issues that arise when a sample is not representative of a population. When developing and testing a vaccine, for example, researchers must make sure to find volunteers from an appropriate proportion of genders, races, age ranges, pre-existing conditions, and so on to test efficacy for the entire population that the vaccine will be used on. If the vaccine manufacturers test on a sample that doesn’t include sufficient data for one race, there is a risk that there could be reduced (if during the initial research phase) or unknown efficacy for that group.\n",
        "\n",
        "It can often be challenging to find a representative sample or even to recognize when there is biased data, but it is essential to think about when designing an experiment."
      ],
      "metadata": {
        "id": "UrH6FmWJMqzC"
      }
    }
  ]
}